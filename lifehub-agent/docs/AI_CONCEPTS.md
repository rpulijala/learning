# AI Concepts Explained (ELI5)

A beginner-friendly guide to the AI concepts used in LifeHub Agent.

---

## Table of Contents

1. [Large Language Models (LLMs)](#1-large-language-models-llms)
2. [Embeddings](#2-embeddings)
3. [Vector Databases](#3-vector-databases)
4. [RAG (Retrieval-Augmented Generation)](#4-rag-retrieval-augmented-generation)
5. [Tool Calling / Function Calling](#5-tool-calling--function-calling)
6. [LangGraph](#6-langgraph)
7. [Multi-Agent Architecture](#7-multi-agent-architecture)
8. [Streaming (SSE)](#8-streaming-sse)
9. [MCP (Model Context Protocol)](#9-mcp-model-context-protocol)
10. [Putting It All Together](#10-putting-it-all-together)

---

## 1. Large Language Models (LLMs)

### What is it?
An LLM is like a super-smart autocomplete. It predicts the next word based on everything it learned from reading billions of documents.

### ELI5
Imagine you read every book, website, and article ever written. Now someone asks you a question, and you answer based on patterns you remember. That's an LLM.

### In LifeHub Agent
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LLM Providers                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OpenAI (Cloud)          â”‚  Ollama (Local)          â”‚
â”‚  â€¢ GPT-4o-mini           â”‚  â€¢ Llama 3.2             â”‚
â”‚  â€¢ Fast, high quality    â”‚  â€¢ Free, private         â”‚
â”‚  â€¢ Requires API key      â”‚  â€¢ Runs on your machine  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Code location**: `backend/models.py`

---

## 2. Embeddings

### What is it?
Embeddings convert text into numbers (vectors) that capture meaning. Similar meanings = similar numbers.

### ELI5
Imagine every word/sentence has a GPS coordinate. "Happy" and "Joyful" are close together. "Happy" and "Refrigerator" are far apart.

### Visual Example
```
Text                    â†’  Embedding (simplified)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"I love running"        â†’  [0.8, 0.2, 0.9, ...]
"I enjoy jogging"       â†’  [0.7, 0.3, 0.9, ...]  â† Similar!
"Buy groceries"         â†’  [0.1, 0.9, 0.2, ...]  â† Different!
```

### Why does this matter?
- **Keyword search**: "running" only matches "running"
- **Semantic search**: "running" also matches "jogging", "marathon", "cardio"

### In LifeHub Agent
```python
# backend/rag/embeddings.py
# Supports both OpenAI and Ollama embeddings

EMBEDDING_PROVIDER=openai  â†’  text-embedding-3-small (1536 dimensions)
EMBEDDING_PROVIDER=ollama  â†’  nomic-embed-text (768 dimensions)
```

---

## 3. Vector Databases

### What is it?
A database optimized for storing and searching embeddings (vectors). Instead of "find exact match", it finds "find similar".

### ELI5
Regular database: "Find all books titled 'Harry Potter'"
Vector database: "Find all books *similar to* Harry Potter" (returns fantasy, magic, coming-of-age stories)

### How it works
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Vector Database                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ID        â”‚  Text                    â”‚  Vector              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  note_1    â”‚  "Monday: 3 mile run"    â”‚  [0.8, 0.2, 0.9...]  â”‚
â”‚  note_2    â”‚  "Pasta recipe..."       â”‚  [0.1, 0.7, 0.3...]  â”‚
â”‚  note_3    â”‚  "Wednesday: tempo run"  â”‚  [0.7, 0.3, 0.8...]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query: "What's my running schedule?"
Query Vector: [0.75, 0.25, 0.85...]

Result: note_1 and note_3 (closest vectors)
```

### In LifeHub Agent
We use **ChromaDB** - an embedded vector database that stores data as files on disk.

```
backend/state/chroma/     â† Vector database files
â”œâ”€â”€ chroma.sqlite3        â† Metadata
â””â”€â”€ [uuid]/               â† Vector data (parquet files)
```

**No external database server needed!** It's just files.

---

## 4. RAG (Retrieval-Augmented Generation)

### What is it?
RAG = "Look it up, then answer"

LLMs only know what they were trained on. RAG lets them access YOUR data by:
1. **Retrieving** relevant information from a knowledge base
2. **Augmenting** the LLM's prompt with that information
3. **Generating** a response using both

### ELI5
It's like an open-book exam. Instead of memorizing everything, you can look up answers in your notes before responding.

### The Problem RAG Solves
```
Without RAG:
User: "What's my running schedule?"
LLM: "I don't have access to your personal schedule."

With RAG:
User: "What's my running schedule?"
System: [Searches notes, finds running plan]
LLM: "Based on your notes, you run Mon/Wed/Fri..."
```

### RAG Pipeline
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INGESTION (one-time setup)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   Markdown     Split into      Embed each       Store in        â”‚
â”‚   Files    â†’   Chunks      â†’   Chunk        â†’   ChromaDB        â”‚
â”‚                (500 chars)     (vectors)        (persist)        â”‚
â”‚                                                                  â”‚
â”‚   fitness.md   ["Monday: 3     [0.8, 0.2...]   ID: fitness_0    â”‚
â”‚                 mile run",     [0.7, 0.3...]   ID: fitness_1    â”‚
â”‚                 "Wednesday:                                      â”‚
â”‚                 tempo..."]                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RETRIEVAL (at query time)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   User Query    Embed         Search           Return Top       â”‚
â”‚              â†’  Query     â†’   ChromaDB     â†’   Matching Chunks  â”‚
â”‚                                                                  â”‚
â”‚   "running      [0.75,        Find similar     "Monday: 3 mile  â”‚
â”‚    schedule"    0.25...]      vectors           run...",        â”‚
â”‚                                                 "Wednesday:      â”‚
â”‚                                                  tempo..."       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GENERATION (final step)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   LLM Prompt:                                                    â”‚
â”‚   "User asked: What's my running schedule?                       â”‚
â”‚                                                                  â”‚
â”‚    Context from notes:                                           â”‚
â”‚    - Monday: 3 mile easy run                                     â”‚
â”‚    - Wednesday: 5 mile tempo run                                 â”‚
â”‚    - Friday: recovery run                                        â”‚
â”‚                                                                  â”‚
â”‚    Please answer based on this context."                         â”‚
â”‚                                                                  â”‚
â”‚   LLM Response: "Your running schedule is..."                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### In LifeHub Agent
```
backend/rag/
â”œâ”€â”€ embeddings.py      # Convert text â†” vectors (OpenAI or Ollama)
â”œâ”€â”€ store.py           # ChromaDB setup
â””â”€â”€ ingest_notes.py    # Ingestion script

backend/tools/
â””â”€â”€ notes.py           # search_notes tool (retrieval)

backend/notes/
â”œâ”€â”€ fitness_example.md # Your notes go here
â””â”€â”€ recipes_example.md
```

---

## 5. Tool Calling / Function Calling

### What is it?
LLMs can't actually DO things - they can only generate text. Tool calling lets them request actions by outputting structured function calls.

### ELI5
The LLM is like a manager who can't use a computer. It writes instructions on paper: "Please look up the weather for Tokyo." A helper (your code) reads the paper, does the task, and reports back.

### How it works
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User: "What's the weather in Tokyo?"                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  LLM thinks: "I need to call the weather tool"                   â”‚
â”‚                                                                  â”‚
â”‚  LLM outputs: {                                                  â”‚
â”‚    "tool": "get_weather",                                        â”‚
â”‚    "arguments": {"city": "Tokyo"}                                â”‚
â”‚  }                                                               â”‚
â”‚                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Your code:                                                      â”‚
â”‚  1. Parses the tool call                                         â”‚
â”‚  2. Executes get_weather("Tokyo")                                â”‚
â”‚  3. Gets result: {"temp": "45Â°F", "conditions": "cloudy"}        â”‚
â”‚  4. Sends result back to LLM                                     â”‚
â”‚                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LLM generates final response:                                   â”‚
â”‚  "The weather in Tokyo is 45Â°F and cloudy."                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### In LifeHub Agent
```
backend/tools/
â”œâ”€â”€ weather.py    # get_weather - calls Open-Meteo API
â”œâ”€â”€ tasks.py      # add_task - writes to tasks.json
â””â”€â”€ notes.py      # search_notes - RAG search
```

Tools are defined with the `@tool` decorator:
```python
@tool
def get_weather(city: str) -> dict:
    """Get current weather for a city."""
    # ... API call ...
    return {"city": city, "temp": "45Â°F", ...}
```

---

## 6. LangGraph

### What is it?
LangGraph is a framework for building multi-step LLM applications as state machines (graphs).

### ELI5
Think of it like a flowchart for your AI:
- **Nodes** = Things to do (call LLM, run tool, etc.)
- **Edges** = What happens next
- **State** = Data that flows through

### Why use it?
```
Without LangGraph:              With LangGraph:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if user_wants_weather:          graph.add_node("planner", ...)
    plan = make_plan()          graph.add_node("worker", ...)
    if plan.has_tools:          graph.add_edge("planner", "worker")
        for tool in plan:       
            result = run(tool)  # Clean, modular, debuggable
            if error:           
                handle_error()  
    response = explain()        
```

### Visual
```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  START  â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚
             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ PLANNER â”‚  â† Creates execution plan
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚
             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ WORKER  â”‚  â† Executes tools
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚
             â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ EXPLAINERâ”‚  â† Generates response
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   END   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### State flows through
```python
class MultiAgentState(TypedDict):
    messages: list          # Conversation history
    plan: list[PlanStep]    # From Planner
    context_log: list       # Tool results from Worker
    final_answer: str       # From Explainer
```

### In LifeHub Agent
**Code location**: `backend/agents/graph.py`

---

## 7. Multi-Agent Architecture

### What is it?
Instead of one LLM doing everything, multiple specialized "agents" work together, each with a specific role.

### ELI5
It's like a restaurant:
- **Planner** = Manager who takes orders and assigns tasks
- **Worker** = Kitchen staff who actually cook
- **Explainer** = Waiter who presents the food nicely

### Why multiple agents?
| Single Agent | Multi-Agent |
|--------------|-------------|
| One prompt does everything | Specialized prompts |
| Hard to debug | Clear responsibility |
| Inconsistent output | Structured flow |
| Can't easily add features | Modular, extensible |

### LifeHub's Three Agents

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PLANNER                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Role: Analyze request, create structured plan                   â”‚
â”‚  Temperature: 0.3 (more deterministic)                           â”‚
â”‚  Output: JSON array of steps                                     â”‚
â”‚                                                                  â”‚
â”‚  Example output:                                                 â”‚
â”‚  [                                                               â”‚
â”‚    {"step": 1, "tool": "search_notes", "input": {...}},         â”‚
â”‚    {"step": 2, "tool": "add_task", "input": {...}},             â”‚
â”‚    {"step": 3, "tool": null, "description": "Synthesize"}       â”‚
â”‚  ]                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         WORKER                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Role: Execute each step in the plan                             â”‚
â”‚  Temperature: 0.2 (very deterministic)                           â”‚
â”‚  Actions: Call tools, log results                                â”‚
â”‚                                                                  â”‚
â”‚  For each step:                                                  â”‚
â”‚  1. If step has tool â†’ execute it                                â”‚
â”‚  2. Log result to context_log                                    â”‚
â”‚  3. Move to next step                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        EXPLAINER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Role: Generate user-friendly response                           â”‚
â”‚  Temperature: 0.7 (more creative)                                â”‚
â”‚  Input: messages + plan + context_log                            â”‚
â”‚  Output: Natural language response (streamed)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. Streaming (SSE)

### What is it?
Server-Sent Events (SSE) allow the server to push data to the client in real-time, token by token.

### ELI5
Without streaming: You wait 10 seconds, then see the entire response at once.
With streaming: You see each word appear as it's generated, like watching someone type.

### How it works
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Without Streaming                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Server       â”‚
â”‚         â”‚  POST /chat                              â”‚             â”‚
â”‚         â”‚                                          â”‚             â”‚
â”‚         â”‚         (waiting... 5 seconds)           â”‚             â”‚
â”‚         â”‚                                          â”‚             â”‚
â”‚         â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚             â”‚
â”‚           "The weather in Tokyo is 45Â°F..."        â”‚             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  With Streaming (SSE)                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Server       â”‚
â”‚         â”‚  POST /chat                              â”‚             â”‚
â”‚         â—„â”€ data: {"token": "The"}                  â”‚             â”‚
â”‚         â—„â”€ data: {"token": " weather"}             â”‚             â”‚
â”‚         â—„â”€ data: {"token": " in"}                  â”‚             â”‚
â”‚         â—„â”€ data: {"token": " Tokyo"}               â”‚             â”‚
â”‚         â—„â”€ data: {"token": " is"}                  â”‚             â”‚
â”‚         â—„â”€ data: {"token": " 45Â°F"}                â”‚             â”‚
â”‚         â—„â”€ data: [DONE]                            â”‚             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### In LifeHub Agent
**Backend** (`main.py`):
```python
async def stream_response(...):
    async for event in graph.astream_events(...):
        if event["event"] == "on_chat_model_stream":
            token = event["data"]["chunk"].content
            yield f"data: {json.dumps({'token': token})}\n\n"
```

**Frontend** (`page.tsx`):
```typescript
const reader = response.body.getReader();
while (true) {
    const { done, value } = await reader.read();
    // Parse SSE data, append token to UI
}
```

---

## 9. MCP (Model Context Protocol)

### What is it?
MCP is an open protocol that lets AI applications connect to external tools and data sources in a standardized way. Think of it as a "USB for AI" - any MCP-compatible tool can plug into any MCP-compatible AI app.

### ELI5
Imagine every AI assistant speaks a different language. MCP is like a universal translator - it lets your AI talk to any tool (web search, databases, file systems) without writing custom code for each one.

### The Problem MCP Solves
```
Without MCP:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your AI App                                                     â”‚
â”‚  â”œâ”€â”€ Custom code for Google Search API                          â”‚
â”‚  â”œâ”€â”€ Custom code for GitHub API                                 â”‚
â”‚  â”œâ”€â”€ Custom code for Slack API                                  â”‚
â”‚  â””â”€â”€ Custom code for every new tool...  ğŸ˜«                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With MCP:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your AI App (MCP Client)                                        â”‚
â”‚  â””â”€â”€ One MCP client that connects to ANY MCP server             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚
         â–¼              â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Search  â”‚   â”‚ GitHub  â”‚   â”‚  Slack  â”‚
    â”‚ Server  â”‚   â”‚ Server  â”‚   â”‚ Server  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How MCP Works
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Architecture                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚  MCP Client  â”‚ â—„â”€â”€â”€â”€â”€â–º â”‚  MCP Server  â”‚                      â”‚
â”‚  â”‚  (Your App)  â”‚  JSON   â”‚  (External)  â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                  â”‚
â”‚  Client actions:           Server provides:                      â”‚
â”‚  â€¢ list_tools()            â€¢ Tool definitions                   â”‚
â”‚  â€¢ call_tool(name, args)   â€¢ Tool execution                     â”‚
â”‚  â€¢ list_resources()        â€¢ Data resources                     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MCP vs Regular APIs

| Aspect | Regular API | MCP |
|--------|-------------|-----|
| Discovery | Read docs, write code | `list_tools()` returns schema |
| Integration | Custom per API | One client for all servers |
| Schema | Varies wildly | Standardized JSON Schema |
| AI-friendly | Not designed for LLMs | Built for AI tool calling |

### In LifeHub Agent

We use MCP as a **client** to connect to external MCP servers like Brave Search:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LifeHub Agent                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Built-in Tools                              â”‚    â”‚
â”‚  â”‚  â€¢ get_weather    â€¢ add_task    â€¢ search_notes          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              +                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              MCP Client                                  â”‚    â”‚
â”‚  â”‚  Dynamically loads tools from MCP servers                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Brave Search    â”‚
                    â”‚  MCP Server      â”‚
                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
                    â”‚  â€¢ brave_web_search
                    â”‚  â€¢ brave_news_search
                    â”‚  â€¢ brave_image_search
                    â”‚  â€¢ brave_video_search
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How LifeHub Integrates MCP

**1. On Startup** - Load tools from configured MCP servers:
```python
# backend/mcp/client.py
async with stdio_client(server_params) as (read, write):
    async with ClientSession(read, write) as session:
        await session.initialize()
        tools = await session.list_tools()  # Get available tools
```

**2. Convert to LangChain** - Wrap MCP tools for our agent:
```python
# MCP tool schema â†’ LangChain StructuredTool
StructuredTool.from_function(
    func=sync_call_mcp_tool,
    name="brave_web_search",
    description="Search the web...",
    args_schema=BraveWebSearchArgs,  # Built from MCP schema
)
```

**3. Agent Uses Them** - Planner can now include MCP tools in plans:
```json
{
  "plan": [
    {"step": 1, "tool": "brave_web_search", "tool_input": {"query": "Python 3.13 features"}},
    {"step": 2, "tool": null, "description": "Summarize results"}
  ]
}
```

### Code Structure
```
backend/mcp/
â”œâ”€â”€ __init__.py      # Package exports
â”œâ”€â”€ config.py        # Server configurations (which MCP servers to connect to)
â””â”€â”€ client.py        # MCP client wrapper (connects, lists tools, calls tools)
```

### Configuration
MCP servers are enabled via environment variables:
```bash
# Enable Brave Search MCP
export BRAVE_API_KEY="your-api-key"

# On startup, LifeHub will:
# 1. Detect BRAVE_API_KEY is set
# 2. Connect to Brave Search MCP server
# 3. Load 6 tools (web_search, news_search, etc.)
# 4. Make them available to the agent
```

### Available MCP Servers
| Server | What it provides | API Key? |
|--------|------------------|----------|
| **Brave Search** | Web, news, image, video search | Yes (free tier) |
| **GitHub** | Repos, issues, PRs | Yes |
| **Filesystem** | Read/write local files | No |
| **Postgres** | Database queries | No |

---

## 10. Putting It All Together

### Complete Request Flow

```
User: "Based on my notes, what's my running plan? Also add a task to buy shoes."

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. FRONTEND                                                      â”‚
â”‚    â€¢ User types message                                          â”‚
â”‚    â€¢ POST /chat with {messages, provider: "openai"}              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. API LAYER (FastAPI)                                           â”‚
â”‚    â€¢ Receives request                                            â”‚
â”‚    â€¢ Converts to LangChain messages                              â”‚
â”‚    â€¢ Invokes LangGraph                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. PLANNER AGENT                                                 â”‚
â”‚    â€¢ Analyzes: "User wants running info + add task"              â”‚
â”‚    â€¢ Creates plan:                                               â”‚
â”‚      [                                                           â”‚
â”‚        {step: 1, tool: "search_notes", input: {query: "running"}}â”‚
â”‚        {step: 2, tool: "add_task", input: {task: "buy shoes"}}   â”‚
â”‚        {step: 3, tool: null, desc: "Synthesize response"}        â”‚
â”‚      ]                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. WORKER AGENT                                                  â”‚
â”‚                                                                  â”‚
â”‚    Step 1: search_notes("running")                               â”‚
â”‚    â”œâ”€ Embed query â†’ [0.75, 0.25, ...]                            â”‚
â”‚    â”œâ”€ Search ChromaDB for similar vectors                        â”‚
â”‚    â””â”€ Return: ["Monday: 3 mile run", "Wednesday: tempo..."]      â”‚
â”‚                                                                  â”‚
â”‚    Step 2: add_task("buy shoes")                                 â”‚
â”‚    â””â”€ Write to tasks.json â†’ Return: "Task added successfully"    â”‚
â”‚                                                                  â”‚
â”‚    Step 3: (no tool, just logged)                                â”‚
â”‚                                                                  â”‚
â”‚    context_log now contains all results                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. EXPLAINER AGENT                                               â”‚
â”‚    â€¢ Receives: messages + plan + context_log                     â”‚
â”‚    â€¢ Calls LLM with all context                                  â”‚
â”‚    â€¢ Streams response token by token                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ (SSE Stream)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. FRONTEND                                                      â”‚
â”‚    â€¢ Receives tokens in real-time                                â”‚
â”‚    â€¢ Displays: "Based on your notes, here's your running plan:   â”‚
â”‚      â€¢ Monday: 3 mile easy run                                   â”‚
â”‚      â€¢ Wednesday: 5 mile tempo run                               â”‚
â”‚      ...                                                         â”‚
â”‚      I've also added 'buy shoes' to your task list!"             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Reference

| Concept | One-liner |
|---------|-----------|
| **LLM** | AI that predicts text based on patterns |
| **Embeddings** | Text â†’ Numbers that capture meaning |
| **Vector DB** | Database for similarity search |
| **RAG** | Look up info, then answer |
| **Tool Calling** | LLM requests actions, code executes them |
| **LangGraph** | Flowchart framework for LLM apps |
| **Multi-Agent** | Specialized LLMs working together |
| **Streaming** | Real-time token-by-token delivery |
| **MCP** | Universal protocol for AI tool integration |

---

## Further Reading

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [RAG Explained (LangChain)](https://python.langchain.com/docs/tutorials/rag/)
- [MCP Protocol Specification](https://modelcontextprotocol.io/)
- [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)
- [Brave Search MCP Server](https://github.com/brave/brave-search-mcp-server)
